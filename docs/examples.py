"""
æ™ºèƒ½ä½“æ¡†æ¶ä½¿ç”¨ç¤ºä¾‹

è¯¥æ–‡ä»¶å±•ç¤ºå¦‚ä½•ä½¿ç”¨è‡ªä¸»æ™ºèƒ½ä½“æ¡†æ¶ï¼Œå‚è€ƒagnoæ¡†æ¶çš„è®¾è®¡æ¨¡å¼

ç¤ºä¾‹åŒ…å«:
- å¤©æ°”æŸ¥è¯¢å·¥å…·
- Pythonä»£ç æ‰§è¡Œå·¥å…·ï¼ˆç®€åŒ–ç‰ˆï¼‰
- HTTPè¯·æ±‚å·¥å…·
- å®Œæ•´çš„Agentä½¿ç”¨ç¤ºä¾‹

åŸºäºagno_test.pyçš„å®é™…ä½¿ç”¨åœºæ™¯
"""

import asyncio
import os
import random
import http.client
import subprocess
import tempfile
from typing import Dict, Any
from pydantic import BaseModel
from loguru import logger

# å¯¼å…¥æˆ‘ä»¬çš„æ¡†æ¶ç»„ä»¶
from simple_agent_lib.schemas import (
    ReasoningChunkEvent,
    ContentChunkEvent,
    ToolCallCompleteEvent,
    AllToolResultsEvent,
)
from simple_agent_lib.tools import tool, get_tool_schemas
from simple_agent_lib.core import LLMAPIClient, AutonomousAgent

from dotenv import load_dotenv

load_dotenv(".env")

# === å·¥å…·å®šä¹‰ ===


class WeatherResponse(BaseModel):
    """å¤©æ°”å“åº”æ¨¡å‹"""

    city: str
    temperature: float
    weather: str


@tool
def get_weather(city: str) -> WeatherResponse:
    """è·å–æŒ‡å®šåŸå¸‚çš„å¤©æ°”ä¿¡æ¯

    Args:
        city: åŸå¸‚åç§°

    Returns:
        WeatherResponse: å¤©æ°”ä¿¡æ¯
    """
    print(f"[å·¥å…·æ‰§è¡Œ] è·å– {city} çš„å¤©æ°”ä¿¡æ¯")
    # raise Exception("æ— æ³•è·å–å¤©æ°”ä¿¡æ¯ï¼Œè¯·æ£€æŸ¥æ‚¨çš„ç½‘ç»œè¿æ¥ï¼") # æµ‹è¯•é”™è¯¯å¤„ç†
    weather_conditions = ["æ™´å¤©", "å¤šäº‘", "é˜´å¤©", "å°é›¨", "å¤§é›¨", "æš´é£é›¨"]
    return WeatherResponse(
        city=city,
        temperature=random.randint(10, 30),
        weather=random.choice(weather_conditions),
    )


@tool
def run_python_code(code: str) -> Dict[str, Any]:
    """æ‰§è¡ŒPythonä»£ç å¹¶è¿”å›ç»“æœ

    Args:
        code: è¦æ‰§è¡Œçš„Pythonä»£ç 

    Returns:
        Dict[str, Any]: æ‰§è¡Œç»“æœï¼ŒåŒ…å«è¾“å‡ºå’Œå¯èƒ½çš„é”™è¯¯
    """
    print(f"[å·¥å…·æ‰§è¡Œ] è¿è¡ŒPythonä»£ç :\n{code}")

    try:
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile(mode="w", suffix=".py", delete=False) as f:
            f.write(code)
            temp_file = f.name

        # æ‰§è¡Œä»£ç 
        result = subprocess.run(
            ["python", temp_file], capture_output=True, text=True, timeout=10
        )

        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        os.unlink(temp_file)

        return {
            "stdout": result.stdout,
            "stderr": result.stderr,
            "returncode": result.returncode,
            "success": result.returncode == 0,
        }
    except subprocess.TimeoutExpired:
        return {
            "stdout": "",
            "stderr": "ä»£ç æ‰§è¡Œè¶…æ—¶",
            "returncode": -1,
            "success": False,
        }
    except Exception as e:
        return {"stdout": "", "stderr": str(e), "returncode": -1, "success": False}


@tool
def http_get_request(hostname: str, path: str = "/", port: int = 80) -> Dict[str, Any]:
    """å‘é€HTTP GETè¯·æ±‚

    Args:
        hostname: ä¸»æœºå
        path: è¯·æ±‚è·¯å¾„
        port: ç«¯å£å·

    Returns:
        Dict[str, Any]: HTTPå“åº”ä¿¡æ¯
    """
    print(f"[å·¥å…·æ‰§è¡Œ] å‘é€HTTPè¯·æ±‚åˆ° {hostname}:{port}{path}")

    try:
        # ä½¿ç”¨http.clientå‘é€è¯·æ±‚
        if port == 443:
            conn = http.client.HTTPSConnection(hostname)
        else:
            conn = http.client.HTTPConnection(hostname, port)

        conn.request("GET", path)
        response = conn.getresponse()

        # è¯»å–å“åº”å†…å®¹ï¼ˆé™åˆ¶å¤§å°é¿å…è¿‡å¤§çš„å“åº”ï¼‰
        content = response.read(10000).decode("utf-8", errors="ignore")

        conn.close()

        return {
            "status_code": response.status,
            "reason": response.reason,
            "headers": dict(response.getheaders()),
            "content": content[:1000] + "..." if len(content) > 1000 else content,
            "content_length": len(content),
        }
    except Exception as e:
        return {"error": str(e), "status_code": 0, "reason": "è¯·æ±‚å¤±è´¥"}


@tool
def calculate_power(base: float, exponent: float) -> Dict[str, Any]:
    """è®¡ç®—å¹‚è¿ç®—

    Args:
        base: åº•æ•°
        exponent: æŒ‡æ•°

    Returns:
        Dict[str, Any]: è®¡ç®—ç»“æœ
    """
    print(f"[å·¥å…·æ‰§è¡Œ] è®¡ç®— {base} çš„ {exponent} æ¬¡å¹‚")

    try:
        result = base**exponent
        return {
            "base": base,
            "exponent": exponent,
            "result": result,
            "calculation": f"{base}^{exponent} = {result}",
        }
    except Exception as e:
        return {"error": str(e), "base": base, "exponent": exponent, "result": None}


# === Agentè®¾ç½®å’Œè¿è¡Œ ===


async def create_agent() -> AutonomousAgent:
    """åˆ›å»ºå¹¶é…ç½®æ™ºèƒ½ä½“"""

    # é…ç½®LLM APIå®¢æˆ·ç«¯
    # æ³¨æ„ï¼šæ‚¨éœ€è¦è®¾ç½®å®é™…çš„APIä¿¡æ¯
    OPENAI_API_BASE = os.getenv(
        "OPENAI_API_BASE", "https://api.openai.com/v1"
    )  # ä¾‹å¦‚: "http://localhost:8000/v1"
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "sk-proj-1234567890")
    LLM_MODEL_NAME = "Qwen3-32B"  # æˆ–æ‚¨ä½¿ç”¨çš„æ¨¡å‹åç§°

    if (
        OPENAI_API_BASE == "YOUR_LLM_API_BASE_URL"
        or OPENAI_API_KEY == "YOUR_LLM_API_KEY"
    ):
        print("âš ï¸  è¯·åœ¨create_agentå‡½æ•°ä¸­é…ç½®æ‚¨çš„LLM APIä¿¡æ¯")
        print("   è®¾ç½® LLM_BASE_URL å’Œ LLM_API_KEY")
        # ä¸ºäº†æ¼”ç¤ºï¼Œæˆ‘ä»¬ä½¿ç”¨æ¨¡æ‹Ÿçš„é…ç½®
        OPENAI_API_BASE = "http://localhost:8000/v1"
        OPENAI_API_KEY = "demo-key"

    # åˆ›å»ºLLMå®¢æˆ·ç«¯
    llm_client = LLMAPIClient(
        base_url=OPENAI_API_BASE, api_key=OPENAI_API_KEY, model_name=LLM_MODEL_NAME
    )

    # åˆ›å»ºAgentï¼Œä¼ å…¥æ‰€æœ‰æ³¨å†Œçš„å·¥å…·
    agent = AutonomousAgent(
        llm_api_client=llm_client,
        tools=[get_weather, run_python_code, http_get_request, calculate_power],
    )

    return agent


async def run_example_task():
    """è¿è¡Œç¤ºä¾‹ä»»åŠ¡ï¼ˆåŸºäºagno_test.pyä¸­çš„ä»»åŠ¡ï¼‰"""

    agent = await create_agent()

    # ä»»åŠ¡æç¤ºï¼ˆæ¥è‡ªagno_test.pyï¼‰
    task_prompt = """
    ä½¿ç”¨Pythonæ¥è°ƒç”¨ http.client æ¥æŸ¥çœ‹ä¸€ä¸‹å¾®è½¯åŸŸåçš„å†…å®¹çœ‹çœ‹ï¼Œ
    ç„¶åå‘Šè¯‰æˆ‘å¾®è½¯æ€»éƒ¨çš„å¤©æ°”å’ŒåŒ—äº¬çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Œ
    ç„¶åè®¡ç®—å¾®è½¯æ€»éƒ¨å¤©æ°”æ¸©åº¦æ•°å€¼çš„åŒ—äº¬å¤©æ°”æ¸©åº¦æ•°å€¼æ¬¡å¹‚ã€‚
    
    è¯·ä¸€æ­¥ä¸€æ­¥çš„å¤„ç†è¿™ä¸ªè¯·æ±‚ï¼Œæ¯æ¬¡è°ƒç”¨å·¥å…·å‰éƒ½å‘Šè¯‰æˆ‘ä½ è¦åšä»€ä¹ˆï¼Œ
    å¹¶ä¸”æ¯æ¬¡å¾—åˆ°å·¥å…·çš„ç»“æœåå‘Šè¯‰æˆ‘ç›®å‰çš„è¿›åº¦ï¼Œå†è¿›è¡Œä¸‹ä¸€æ­¥ã€‚
    """

    print("ğŸš€ å¼€å§‹æ‰§è¡Œä»»åŠ¡...")
    print(f"ğŸ“ ä»»åŠ¡: {task_prompt.strip()}")
    print("\n" + "=" * 50)

    # è¿è¡ŒAgent
    try:
        has_reasoning = False
        reasoning_content = []

        async for event in agent.run(initial_prompt=task_prompt, stream_mode=True):
            if isinstance(event, ReasoningChunkEvent):
                if not has_reasoning:
                    print("\nğŸ¤” [æ¨ç†è¿‡ç¨‹]:", end="")
                    has_reasoning = True
                print(event.text, end="", flush=True)
                reasoning_content.append(event.text)
            elif isinstance(event, ContentChunkEvent):
                if has_reasoning:
                    print("\n\nğŸ’¬ [AIå›å¤]:", end="")
                    has_reasoning = False
                print(event.text, end="", flush=True)
            elif isinstance(event, ToolCallCompleteEvent):
                print(f"\nğŸ”§ è°ƒç”¨å·¥å…·: {event.tool_call.name}")
            elif isinstance(event, AllToolResultsEvent):
                print("âœ… å·¥å…·æ‰§è¡Œå®Œæˆ")
                
        logger.info(f"å®Œæ•´ä¸Šä¸‹æ–‡ï¼š{agent.context.messages}")

    except Exception as e:
        print(f"âŒ ä»»åŠ¡æ‰§è¡Œå‡ºé”™: {e}")
        import traceback

        traceback.print_exc()


async def simple_weather_example():
    """ç®€å•çš„å¤©æ°”æŸ¥è¯¢ç¤ºä¾‹"""

    agent = await create_agent()

    print("\nğŸŒ¤ï¸  ç®€å•å¤©æ°”æŸ¥è¯¢ç¤ºä¾‹")
    print("=" * 30)

    prompt = "è¯·å‘Šè¯‰æˆ‘åŒ—äº¬å’Œä¸Šæµ·çš„å¤©æ°”æƒ…å†µï¼Œå¹¶æ¯”è¾ƒä¸€ä¸‹å“ªä¸ªåŸå¸‚æ›´é€‚åˆå¤–å‡ºã€‚"

    # ç”¨äºè·Ÿè¸ªæ˜¯å¦æœ‰æ¨ç†å†…å®¹
    has_reasoning = False
    reasoning_content = []

    async for event in agent.run(initial_prompt=prompt, stream_mode=True):
        if isinstance(event, ReasoningChunkEvent):
            if not has_reasoning:
                print("\nğŸ¤” [æ¨ç†è¿‡ç¨‹]:", end="")
                has_reasoning = True
            print(event.text, end="", flush=True)
            reasoning_content.append(event.text)
        elif isinstance(event, ContentChunkEvent):
            if has_reasoning:
                print("\n\nğŸ’¬ [AIå›å¤]:", end="")
                has_reasoning = False
            print(event.text, end="", flush=True)
        elif isinstance(event, ToolCallCompleteEvent):
            print(f"\nğŸ”§ è°ƒç”¨å·¥å…·: {event.tool_call.name}")
        elif isinstance(event, AllToolResultsEvent):
            print("âœ… å·¥å…·æ‰§è¡Œå®Œæˆ")
            
    logger.info(f"å®Œæ•´ä¸Šä¸‹æ–‡ï¼š{agent.context.messages}")

    # å¦‚æœæ•è·åˆ°äº†æ¨ç†å†…å®¹ï¼Œæ˜¾ç¤ºæ€»ç»“
    if reasoning_content:
        print(f"\n\nğŸ“ æœ¬æ¬¡ä¼šè¯å…±æ•è·æ¨ç†å†…å®¹: {len(reasoning_content)} ä¸ªç‰‡æ®µ")
        full_reasoning = "".join(reasoning_content)
        print(f"ğŸ“Š æ¨ç†å†…å®¹æ€»é•¿åº¦: {len(full_reasoning)} å­—ç¬¦")
    else:
        print("\n\nğŸ“ æœ¬æ¬¡ä¼šè¯æœªæ£€æµ‹åˆ°æ¨ç†å†…å®¹ï¼ˆå¯èƒ½ä½¿ç”¨çš„æ˜¯éæ¨ç†æ¨¡å‹ï¼‰")


def show_registered_tools():
    """æ˜¾ç¤ºæ‰€æœ‰æ³¨å†Œçš„å·¥å…·ä¿¡æ¯"""
    print("\nğŸ› ï¸  å·²æ³¨å†Œçš„å·¥å…·:")
    print("=" * 20)

    # registry = get_tool_registry()
    schemas = get_tool_schemas()

    for schema in schemas:
        func_info = schema["function"]
        name = func_info["name"]
        description = func_info["description"]
        params = func_info["parameters"]["properties"]

        print(f"ğŸ“Œ {name}")
        print(f"   æè¿°: {description}")
        print(f"   å‚æ•°: {list(params.keys())}")
        print()


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¤– è‡ªä¸»æ™ºèƒ½ä½“æ¡†æ¶ç¤ºä¾‹")
    print("åŸºäºagnoæ¡†æ¶è®¾è®¡æ¨¡å¼")
    print("=" * 40)

    # æ˜¾ç¤ºå·¥å…·ä¿¡æ¯
    show_registered_tools()

    # è¿è¡Œç®€å•ç¤ºä¾‹
    await simple_weather_example()

    print("\n" + "=" * 50)
    print("ä¸»è¦ä»»åŠ¡æ¼”ç¤º:")

    await run_example_task()


if __name__ == "__main__":
    # è¿è¡Œç¤ºä¾‹
    asyncio.run(main())
