#!/usr/bin/env python3
"""
æµ‹è¯•å·¥å…·è°ƒç”¨æ—¶æ–‡æœ¬å†…å®¹çš„ä¿å­˜
"""

import asyncio
import os
import sys
from typing import Dict, Any
from pydantic import BaseModel

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from simple_agent_lib import LLMAPIClient, Agent, Context, tool
from simple_agent_lib.schemas import (
    ContentChunkEvent,
    ToolCallCompleteEvent,
    AllToolResultsEvent,
)


@tool
def simple_calculator(a: float, b: float) -> Dict[str, Any]:
    """ç®€å•è®¡ç®—å™¨"""
    return {"result": a + b, "operation": f"{a} + {b} = {a + b}"}


async def create_test_agent() -> Agent:
    """åˆ›å»ºæµ‹è¯•ç”¨çš„Agent"""
    api_base = os.getenv("OPENAI_API_BASE", "http://localhost:8000/v1")
    api_key = os.getenv("OPENAI_API_KEY", "test-key")
    model_name = os.getenv("LLM_MODEL_NAME", "gemini-2.5-flash")
    
    llm_client = LLMAPIClient(
        base_url=api_base,
        api_key=api_key,
        model_name=model_name
    )
    
    agent = Agent(
        llm_api_client=llm_client,
        tools=[simple_calculator],
        system_prompt="ä½ æ˜¯ä¸€ä¸ªæ•°å­¦åŠ©æ‰‹ï¼Œåœ¨ä½¿ç”¨å·¥å…·å‰åéƒ½è¦è¯´æ˜ä½ åœ¨åšä»€ä¹ˆã€‚",
        debug_mode=True
    )
    
    return agent


async def test_tool_call_with_text():
    """æµ‹è¯•å·¥å…·è°ƒç”¨æ—¶çš„æ–‡æœ¬å†…å®¹ä¿å­˜"""
    print("ğŸ§ª æµ‹è¯•å·¥å…·è°ƒç”¨æ—¶çš„æ–‡æœ¬å†…å®¹ä¿å­˜...")
    
    agent = await create_test_agent()
    
    # ä½¿ç”¨ä¸€ä¸ªä¼šè§¦å‘å·¥å…·è°ƒç”¨å¹¶äº§ç”Ÿæ–‡æœ¬è¯´æ˜çš„æç¤º
    prompt = "è¯·è®¡ç®— 5 + 3ï¼Œåœ¨è®¡ç®—å‰è¯´æ˜ä½ è¦åšä»€ä¹ˆï¼Œåœ¨è®¡ç®—åè¯´æ˜ç»“æœã€‚"
    print(f"ç”¨æˆ·è¾“å…¥: {prompt}")
    
    content_chunks = []
    tool_calls = []
    
    print("\n=== æµå¼æ¨¡å¼ ===")
    async for event in agent.run(initial_prompt=prompt, stream_mode=True):
        if isinstance(event, ContentChunkEvent):
            content_chunks.append(event.text)
            print(f"[å†…å®¹] {event.text}", end="")
        elif isinstance(event, ToolCallCompleteEvent):
            tool_calls.append(event.tool_call)
            print(f"\n[å·¥å…·] {event.tool_call.name}({event.tool_call.args})")
        elif isinstance(event, AllToolResultsEvent):
            print(f"\n[ç»“æœ] å·¥å…·æ‰§è¡Œå®Œæˆ")
    
    print(f"\n\næ”¶é›†åˆ°çš„å†…å®¹: {''.join(content_chunks)}")
    print(f"å·¥å…·è°ƒç”¨æ¬¡æ•°: {len(tool_calls)}")
    
    # åˆ†æä¸Šä¸‹æ–‡
    context_messages = agent.context.to_openai_messages()
    print(f"\n=== ä¸Šä¸‹æ–‡åˆ†æ ===")
    print(f"æ¶ˆæ¯æ€»æ•°: {len(context_messages)}")
    
    for i, msg in enumerate(context_messages, 1):
        role = msg.get('role', 'æœªçŸ¥')
        content = (msg.get('content', '') or '')[:100] + "..." if len((msg.get('content', '') or '')) > 100 else (msg.get('content', '') or '')
        tool_calls_count = len(msg.get('tool_calls', []))
        
        print(f"  {i}. {role}: '{content}' (å·¥å…·è°ƒç”¨: {tool_calls_count})")
    
    # æ£€æŸ¥å…³é”®é—®é¢˜ï¼šæ˜¯å¦æœ‰assistantæ¶ˆæ¯åŒæ—¶åŒ…å«æ–‡æœ¬å†…å®¹å’Œå·¥å…·è°ƒç”¨ï¼Ÿ
    assistant_messages = [msg for msg in context_messages if msg.get('role') == 'assistant']
    
    print(f"\n=== å…³é”®æ£€æŸ¥ ===")
    for i, msg in enumerate(assistant_messages, 1):
        has_content = bool(msg.get('content'))
        has_tools = bool(msg.get('tool_calls'))
        
        if has_tools:
            if has_content:
                print(f"âœ… åŠ©æ‰‹æ¶ˆæ¯ {i}: åŒæ—¶åŒ…å«å·¥å…·è°ƒç”¨å’Œæ–‡æœ¬å†…å®¹")
                print(f"   æ–‡æœ¬: '{msg.get('content', '')[:50]}...'")
            else:
                print(f"âŒ åŠ©æ‰‹æ¶ˆæ¯ {i}: åªæœ‰å·¥å…·è°ƒç”¨ï¼Œç¼ºå°‘æ–‡æœ¬å†…å®¹")
        elif has_content:
            print(f"âœ… åŠ©æ‰‹æ¶ˆæ¯ {i}: çº¯æ–‡æœ¬å›å¤")
    
    # æ£€æŸ¥æ˜¯å¦å­˜åœ¨é—®é¢˜
    tool_with_text_count = sum(1 for msg in assistant_messages 
                               if msg.get('tool_calls') and msg.get('content'))
    tool_without_text_count = sum(1 for msg in assistant_messages 
                                  if msg.get('tool_calls') and not msg.get('content'))
    
    print(f"\nğŸ“Š ç»Ÿè®¡:")
    print(f"æœ‰å·¥å…·è°ƒç”¨ä¸”æœ‰æ–‡æœ¬çš„åŠ©æ‰‹æ¶ˆæ¯: {tool_with_text_count}")
    print(f"æœ‰å·¥å…·è°ƒç”¨ä½†æ— æ–‡æœ¬çš„åŠ©æ‰‹æ¶ˆæ¯: {tool_without_text_count}")
    
    if tool_without_text_count > 0 and len(content_chunks) > 0:
        print(f"âš ï¸  å‘ç°é—®é¢˜ï¼šLLMäº§ç”Ÿäº†æ–‡æœ¬å†…å®¹ï¼ˆ{len(content_chunks)}ä¸ªå—ï¼‰ï¼Œä½†éƒ¨åˆ†å·¥å…·è°ƒç”¨æ¶ˆæ¯ä¸­æ²¡æœ‰åŒ…å«æ–‡æœ¬å†…å®¹ï¼")
        return False
    else:
        print(f"âœ… æµ‹è¯•é€šè¿‡ï¼šå·¥å…·è°ƒç”¨å’Œæ–‡æœ¬å†…å®¹éƒ½è¢«æ­£ç¡®ä¿å­˜")
        return True


def main():
    """ä¸»å‡½æ•°"""
    return asyncio.run(test_tool_call_with_text())


if __name__ == "__main__":
    success = main()
    exit(0 if success else 1) 