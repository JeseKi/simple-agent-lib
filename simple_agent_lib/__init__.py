"""
Agent Lib - æ™ºèƒ½ä½“æ¡†æ¶åº“

æä¾›ä¸Šä¸‹æ–‡è®°å¿†ã€å·¥å…·è°ƒç”¨å’ŒLLMäº¤äº’åŠŸèƒ½çš„Pythonåº“ã€‚

ä¸»è¦åŠŸèƒ½:
- ğŸ§  æ™ºèƒ½ä¸Šä¸‹æ–‡è®°å¿† - è‡ªåŠ¨ç®¡ç†å¯¹è¯å†å²ï¼Œæ”¯æŒtokenå’Œæ¶ˆæ¯æ•°é‡é™åˆ¶
- ğŸ› ï¸ å·¥å…·è°ƒç”¨ç³»ç»Ÿ - è£…é¥°å™¨å¼å·¥å…·å®šä¹‰ï¼Œè‡ªåŠ¨å‚æ•°éªŒè¯
- ğŸ¤– LLMäº¤äº’æ¡†æ¶ - ç»Ÿä¸€çš„OpenAI APIæ¥å£
- âš¡ å¼‚å¸¸å¤„ç† - æ™ºèƒ½çš„é”™è¯¯å¤„ç†å’Œæ¢å¤ç­–ç•¥

ä½¿ç”¨ç¤ºä¾‹:
    from simple_agent_lib import Agent, LLMAPIClient, tool

    @tool
    def get_weather(city: str) -> str:
        return f"{city}ä»Šå¤©æ™´æœ—ï¼Œæ¸©åº¦25Â°C"

    llm_client = LLMAPIClient("https://api.openai.com/v1", "your-key", "gpt-4")

    # ç”Ÿäº§ç¯å¢ƒ - é»˜è®¤æ— æ—¥å¿—
    agent = Agent(llm_api_client=llm_client)

    # å¼€å‘ç¯å¢ƒ - å¯ç”¨æ—¥å¿—
    agent = Agent(llm_api_client=llm_client, debug_mode=True)

    async for event in agent.run("åŒ—äº¬å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"):
        if hasattr(event, 'text'):
            print(event.text, end='')
"""

__version__ = "1.2.0"
__author__ = "Jese Ki"
__email__ = "209490107@qq.com"
__description__ = "æ™ºèƒ½ä½“æ¡†æ¶åº“ - æä¾›ä¸Šä¸‹æ–‡è®°å¿†ã€å·¥å…·è°ƒç”¨å’ŒLLMäº¤äº’åŠŸèƒ½"

from .schemas import (
    ToolCall,
    ToolResult,
    LLMOutput,
    AgentStreamEvent,
    ReasoningChunkEvent,
    ContentChunkEvent,
    ToolCallCompleteEvent,
    AllToolResultsEvent,
    LLMEndReasonEvent,
    Context,
    ContextMessage,
)

from .tools import tool, get_tool_schemas, get_tool_registry, clear_tools

from .core import Agent

from .client import LLMAPIClient

from .logger_config import (
    enable_logging,
    disable_logging,
    is_logging_enabled,
    setup_logger,
)

from .exceptions import (
    ContextTokenLimitExceededError,
    ContextManagementError,
    ToolExecutionError,
    LLMInteractionError,
)

__all__ = [
    # æ ¸å¿ƒç±»
    "LLMAPIClient",
    "Agent",
    # å·¥å…·ç›¸å…³
    "tool",
    "get_tool_schemas",
    "get_tool_registry",
    "clear_tools",
    # æ—¥å¿—æ§åˆ¶
    "enable_logging",
    "disable_logging",
    "is_logging_enabled",
    "setup_logger",
    # ç±»å‹å®šä¹‰
    "ToolCall",
    "ToolResult",
    "LLMOutput",
    "AgentStreamEvent",
    "ReasoningChunkEvent",
    "ContentChunkEvent",
    "ToolCallCompleteEvent",
    "AllToolResultsEvent",
    "LLMEndReasonEvent",
    # ä¸Šä¸‹æ–‡è®°å¿†
    "Context",
    "ContextMessage",
    # å¼‚å¸¸ç±»
    "ContextTokenLimitExceededError",
    "ContextManagementError",
    "ToolExecutionError",
    "LLMInteractionError",
]
